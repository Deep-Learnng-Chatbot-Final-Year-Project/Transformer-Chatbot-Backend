# Transformer-based Conversational Chatbot Backend using FastAPI

This is a repository for a conversational chatbot backend that is built using the transformer architecture and FastAPI. The chatbot is designed to answer general questions and have conversations with the users.

## Requirements

To run the code in this repository, you need to have the following software installed on your system:

- Python 3.x
- TensorFlow 2.x
- FastAPI

You also need to have a GPU if you want to train the model yourself, as the training process can be quite slow on a CPU.

## Deployment

To deploy the chatbot backend, run the following command:


```
uvicorn main:app --reload
```

This will launch the FastAPI server and make the chatbot available through a REST API.

## Contributing

If you want to contribute to this project, please feel free to open a pull request. We welcome all contributions, including bug fixes, improvements to the code, and new features.

## License

This repository is released under the MIT License. See the LICENSE file for more information.
